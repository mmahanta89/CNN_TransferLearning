{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, concatenate, Input, Conv2D, MaxPooling2D\n",
    "from keras.optimizers import Adam, Adadelta\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Viewing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "rootdir='F:\\\\GreatLearning\\\\AI\\\\ComputerVision\\\\Project\\\\plant_seeding_classification_data\\\\train\\\\'\n",
    "\n",
    "for file in os.listdir(rootdir):\n",
    "    d = os.path.join(rootdir, file)\n",
    "    if os.path.isdir(d):\n",
    "        print(file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We have 12 species of plants avaialable for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(rootdir):\n",
    "    d = os.path.join(rootdir, file)\n",
    "    if os.path.isdir(d):\n",
    "        print(file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "os.chdir(d)\n",
    "count=0\n",
    "imgList=[]\n",
    "for file in glob.glob(\"*.PNG\"):\n",
    "    print(file)\n",
    "    count+=1\n",
    "    imgList.append(file)\n",
    "    if (count==10):\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From first glance, images are in png format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1= os.path.join(d, imgList[0])\n",
    "\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#function created for viewing basic data features of images\n",
    "def imgBasics(path,imgName):\n",
    "    img1= os.path.join(path, imgName)\n",
    "    pic = imageio.imread(img1)\n",
    "    plt.figure(figsize = (5,5))\n",
    "    plt.imshow(pic)\n",
    "\n",
    "    #Basic properties of image\n",
    "    print('Type of the image : ' , type(pic)) \n",
    "    print('Shape of the image : {}'.format(pic.shape)) \n",
    "    print('Image Hight {}'.format(pic.shape[0])) \n",
    "    print('Image Width {}'.format(pic.shape[1])) \n",
    "    print('Dimension of Image {}'.format(pic.ndim))\n",
    "    print('Image size {}'.format(pic.size)) \n",
    "    print('Maximum RGB value in this image {}'.format(pic.max())) \n",
    "    print('Minimum RGB value in this image {}'.format(pic.min()))\n",
    "    print('Value of only R channel {}'.format(pic[ 100, 50, 0])) \n",
    "    print('Value of only G channel {}'.format(pic[ 100, 50, 1])) \n",
    "    print('Value of only B channel {}'.format(pic[ 100, 50, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgBasics(d,imgList[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgBasics(d,imgList[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgBasics(d,imgList[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "imgBasics(d,imgList[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pic = imageio.imread(img1) \n",
    "gray = lambda rgb : np.dot(rgb[... , :3] , [0.299 , 0.587, 0.114]) \n",
    "gray = gray(pic) \n",
    "plt.figure( figsize = (5,5))  \n",
    "plt.imshow(gray, cmap = plt.get_cmap(name = 'gray')) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "pic = imageio.imread(img1) \n",
    "fig, ax = plt.subplots(nrows = 1, ncols=3, figsize=(15,5))  \n",
    "for c, ax in zip(range(3), ax):     \n",
    "     split_img = np.zeros(pic.shape, dtype=\"uint8\")       \n",
    "     split_img[ :, :, c] = pic[ :, :, c]     \n",
    "     ax.imshow(split_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Images are of very diferent resolutions, ranging from 1023x1023 to 481x481\n",
    "- they have 3 channnels (RGB)\n",
    "- Lot of details avialable apart from just the plant species like sand grains or stone or scales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploring the folders containing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Understaanding data for loading\n",
    "train_dir = 'F:/GreatLearning/AI/ComputerVisionProject/plant_seeding_classification_data/train'\n",
    "test_dir  = 'F:/GreatLearning/AI/ComputerVisionProject/plant_seeding_classification_data/test'\n",
    "sample_submission = pd.read_csv('F:\\GreatLearning\\AI\\ComputerVision\\Project\\plant_seeding_classification_data\\sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_immediate_subdirectories(a_dir):\n",
    "    return [name for name in os.listdir(a_dir)\n",
    "            if os.path.isdir(os.path.join(a_dir, name))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specPath='F:\\\\GreatLearning\\\\AI\\\\ComputerVision\\\\Project\\\\plant_seeding_classification_data\\\\train\\\\'\n",
    "specPathTest='F:\\\\GreatLearning\\\\AI\\\\ComputerVision\\\\Project\\\\plant_seeding_classification_data\\\\test\\\\'\n",
    "cat_Folder_list=get_immediate_subdirectories(specPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List of species in the train folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plant_Species=cat_Folder_list\n",
    "print('List od Plant species: ', Plant_Species)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nummber of images in the train sub folders along with categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#No. of images under each plant species foler for train\n",
    "for img in Plant_Species:\n",
    "    print('{}   -->   {} training images'.format(img, len(os.listdir(os.path.join(specPath, img)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We have 12 species and all flowers have varying data for training\n",
    "- Loose silky-bent has highest concentration of images having 671 images and common wheat has of 221 images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data from all folders along with mapped categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Importing data\n",
    "- Preprocessing the image for using it in models\n",
    "- For Supervised Models like KNN, \n",
    "    - importing and resizing it to 32x32 with RGB to maintain its colours and pattern (COLOR_BGR2RGB)\n",
    "    - For Interpolation using cv.INTER_AREA\n",
    "    - dividing the values with 255 to normalize it and make it float\n",
    "    - capturing the folder names as categories\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can not directly use the image, we have to process the image.\n",
    "\n",
    "from pathlib import Path\n",
    "from skimage.io import imread\n",
    "from keras.preprocessing import image\n",
    "import cv2 as cv\n",
    "def load_image_files(container_path):\n",
    "    image_dir = Path(container_path)\n",
    "    folders = [directory for directory in image_dir.iterdir() if directory.is_dir()]\n",
    "    categories = [fo.name for fo in folders]\n",
    "\n",
    "    images = []\n",
    "    flat_data = []\n",
    "    target = []\n",
    "    count = 0\n",
    "    train_img = []\n",
    "    label_img = []\n",
    "    for i, direc in enumerate(folders):\n",
    "        for file in direc.iterdir():\n",
    "            count += 1\n",
    "            img = imread(file)\n",
    "            img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "            img_pred = cv.resize(img, (32, 32), interpolation=cv.INTER_AREA)\n",
    "            img_pred = image.img_to_array(img_pred)\n",
    "            img_pred = img_pred / 255\n",
    "            train_img.append(img_pred)\n",
    "            label_img.append(categories[i])\n",
    "            \n",
    "    X = np.array(train_img)\n",
    "    y = np.array(label_img)\n",
    "    return X,y\n",
    "\n",
    "#Using the Keras pre-processing library the image is converted to an array and then normalised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "X,y = load_image_files(specPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exploring shape of imported data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploring images captured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(X[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(X[0],cmap='gist_earth')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(15,15))\n",
    "\n",
    "for i in range(1,101):\n",
    "  img=X[i]\n",
    "  fig.add_subplot(10,10,i)\n",
    "  plt.imshow(img,cmap='gray')\n",
    "\n",
    "plt.show()\n",
    "print('Label: ', y[1:101])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(15,15))\n",
    "\n",
    "for i in range(1,101):\n",
    "  img=X[1000+i]\n",
    "  fig.add_subplot(10,10,i)\n",
    "  plt.imshow(img)\n",
    "\n",
    "plt.show()\n",
    "print('Label: ', y[1001:1101])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image analysis \n",
    "- Images are not simple \n",
    "- Contains foreground and background details with multiple objects as noise in it like rulers, stones, soil, sand, corners, alphabets\n",
    "- Huge variations of data present\n",
    "- Images are not focused as well\n",
    "- Actual plants are covering very less pixels compared to background and noise. This will lead to high class imbalance for target object and noise.\n",
    "- Simple supervised models will have hard time filtering the actual plants with soil and stones as they see the whole picture as a single input and are not splitting foreground from background."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating data sets for training and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Splitting Whole data set to Train, Val and Test with 80%, 10%, 10% respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, random_state=42, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View data set shape\n",
    "print(\"X_train: \"+str(X_train.shape))\n",
    "print(\"X_test: \"+str(X_test.shape))\n",
    "print(\"X_val: \"+str(X_val.shape))\n",
    "print(\"y_train: \"+str(y_train.shape))\n",
    "print(\"y_test: \"+str(y_test.shape))\n",
    "print(\"y_val: \"+str(y_val.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View Raw data in train set\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshaping Data sets for using in KNN model\n",
    "\n",
    "from builtins import range\n",
    "from builtins import object\n",
    "\n",
    "num_training = X_train.shape[0]\n",
    "mask = list(range(num_training))\n",
    "X_train = X_train[mask]\n",
    "y_train = y_train[mask]\n",
    "\n",
    "num_test = X_test.shape[0]\n",
    "mask = list(range(num_test))\n",
    "X_test = X_test[mask]\n",
    "y_test = y_test[mask]\n",
    "\n",
    "num_val = X_val.shape[0]\n",
    "mask = list(range(num_val))\n",
    "X_val = X_val[mask]\n",
    "y_val = y_val[mask]\n",
    "\n",
    "# Reshape the image data into rows\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
    "X_val = np.reshape(X_val, (X_val.shape[0], -1))\n",
    "\n",
    "print(\"X_train: \"+str(X_train.shape))\n",
    "print(\"X_test: \"+str(X_test.shape))\n",
    "print(\"X_val: \"+str(X_val.shape))\n",
    "print(\"y_train: \"+str(y_train.shape))\n",
    "print(\"y_test: \"+str(y_test.shape))\n",
    "print(\"y_val: \"+str(y_val.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y.view())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image classification with KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KNN\n",
    "- For Plant species raw data, expectations is the leaf's and other patern remain close to each other and a KNN model will be able pick up the common features and group it together\n",
    "- k-nearest neighbor algorithm is for classifying objects based on closest training examples in the feature space. k-nearest neighbor algorithm is among the simplest of all machine learning algorithms. Training process for this algorithm only consists of storing feature vectors and labels of the training images. In the classification process, the unlabelled query point is simply assigned to the label of its k nearest neighbors.\n",
    "- A main advantage of the KNN algorithm is that it performs well with multi-modal classes because the basis of its decision is based on a small neighborhood of similar objects. Therefore, even if the target class is multi-modal, the algorithm can still lead to good accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix,recall_score,f1_score,precision_score,roc_curve,log_loss,auc\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "#KNN Model with 1 neighbour\n",
    "\n",
    "KnnModel = KNeighborsClassifier(n_neighbors=1)\n",
    "KnnModel.fit(X_train,y_train)\n",
    "y_predict=KnnModel.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Accuracy score:',accuracy_score(y_test,y_predict))\n",
    "print('confuion matrix:\\n',confusion_matrix(y_test,y_predict))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- With single neighbour we are able to acheive close to 30% accuracy, but 1 neighbour is higly volatile and wont give us generalised result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the value of k and finding the accuracies on validation data\n",
    "k_vals = range(1, 30, 2)\n",
    "accuracies = []\n",
    "\n",
    "for k in range(1, 30, 2):\n",
    "  knn = KNeighborsClassifier(n_neighbors=k)\n",
    "  knn.fit(X_train, y_train)\n",
    "  score = knn.score(X_val, y_val)\n",
    "  print(\"k value=%d, accuracy score=%.2f%%\" % (k, score * 100))\n",
    "  accuracies.append(score)\n",
    " \n",
    "# finding the value of k which has the largest accuracy\n",
    "i = int(np.argmax(accuracies))\n",
    "print(\"k=%d value has highest accuracy of %.2f%% on validation data\" % (k_vals[i],accuracies[i] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Even though we got highest accuracies at 1 neighbour but we will go ahead with k=25 for more generalized approach which showed similar high accuracies on validation data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=25)\n",
    "knn.fit(X_train, y_train)\n",
    "predictions = knn.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"EVALUATION ON TESTING DATA\")\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2,2))\n",
    "plt.imshow(X_test[59].reshape(32,32,3))\n",
    "plt.show()\n",
    "image = X_test[59]\n",
    "print('Prediction:',knn.predict(image.reshape(1, -1)))\n",
    "print('Actual:',y_test[59])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2,2))\n",
    "plt.imshow(X_test[300].reshape(32,32,3))\n",
    "plt.show()\n",
    "image = X_test[300]\n",
    "print('Prediction:',knn.predict(image.reshape(1, -1)))\n",
    "print('Actual:',y_test[300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictions = knn.predict(X_test)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Accuracies from KNN are close to 24%.\n",
    "- We can observe on each classes precision and recall are very low.\n",
    "- Model is not able to identify and split relevent data from rest of the noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For Plant species raw data, expectations is the leaf's and other patern remain close to each other and a KNN model will be able pick up the common features and group it together.\n",
    "- While data analysis we noticed the images contains lot of noise or i few images actual plat is hardly cvering 5% of total pixels\n",
    "- Executed KNN from 1 to 30 neighbours and identified best values were at 1 neighbour and 25 neighbours. We chose for 25 neighbours so that we will get a more generalized prediction on classification.\n",
    "- With KNN our classification accuracies were close to 20% which are way below acceptable levels\n",
    "- We can observe there is an underlying pattern to the images for both raw pixel intensities and color. KNN is not capable enough to understand the differences and classifymore accurately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Issues with KNN\n",
    "- KNN depends on nearest neighbours, which might not be the best choice all the time. Observed the same issue during our evaluation proces as well\n",
    "- a major disadvantage of the KNN algorithm is that it uses all the features equally in computing for similarities. This can lead to classification errors, especially when there is only a small subset of features that are useful for classification. \n",
    "- While data analysis we noticed the images contains lot of noise or in few images actual plant is hardly cvering 5% of total pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image classification with Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using One hot encoder to convert the categories to array formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "one_hot_encoder.fit(y_train.reshape(-1, 1))\n",
    "\n",
    "y_train = one_hot_encoder.transform(y_train.reshape(-1, 1))\n",
    "#y_train = pd.DataFrame(data=y_train, columns=one_hot_encoder.categories_)\n",
    "\n",
    "y_test = one_hot_encoder.transform(y_test.reshape(-1, 1))\n",
    "#y_test = pd.DataFrame(data=y_test, columns=one_hot_encoder.categories_)\n",
    "\n",
    "y_val = one_hot_encoder.transform(y_val.reshape(-1, 1))\n",
    "#y_val = pd.DataFrame(data=y_val, columns=one_hot_encoder.categories_)\n",
    "\n",
    "\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "\n",
    "print(\"Shape of y_test:\", y_test.shape)\n",
    "\n",
    "print(\"Shape of y_val:\", y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_cat = pd.DataFrame(data=y_test, columns=one_hot_encoder.categories_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Activation\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.layers import BatchNormalization, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10000,kernel_initializer='he_normal'))\n",
    "model.add(BatchNormalization())                    \n",
    "model.add(Activation('relu'))    \n",
    "model.add(Dense(5000,kernel_initializer='he_normal'))\n",
    "model.add(BatchNormalization())                    \n",
    "model.add(Activation('relu'))    \n",
    "model.add(Dense(1000,kernel_initializer='he_normal'))\n",
    "model.add(BatchNormalization())                    \n",
    "model.add(Activation('relu'))    \n",
    "model.add(Dense(500,kernel_initializer='he_normal'))\n",
    "model.add(BatchNormalization())                    \n",
    "model.add(Activation('relu')) \n",
    "model.add(Dense(250,kernel_initializer='he_normal'))\n",
    "model.add(BatchNormalization())                    \n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(125,kernel_initializer='he_normal'))\n",
    "model.add(BatchNormalization())                    \n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(32,kernel_initializer='he_normal'))\n",
    "model.add(BatchNormalization())                    \n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(12,kernel_initializer='he_normal'))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "#updating learning rate\n",
    "adam = optimizers.Adam(lr=0.009, decay=1e-5)\n",
    "# Compile the model\n",
    "model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=\"adam\")\n",
    "\n",
    "# Fit the model\n",
    "model.fit(x=X_train, y=y_train, batch_size=50, epochs=10, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(X_test, y_test)\n",
    "print('Accuracy: %f ' % (results[1]*100))\n",
    "print('Loss: %f' % results[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Acheived a accuracy more than 32% on Test dataset as compared to 24% on KNN\n",
    "- Will try to further finetune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_test_cls = (model.predict(X_test) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2,2))\n",
    "plt.imshow(X_test[300].reshape(32,32,3))\n",
    "plt.show()\n",
    "\n",
    "print('Label - one hot encoded: ',y_test_cat.iloc[300] )\n",
    "print('Actual Label - one hot encoded:  ', y_test[300])\n",
    "print('Predicted Label - one hot encoded: ',Y_pred_test_cls[300] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NN Approach 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reducing complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1000,kernel_initializer='he_normal'))\n",
    "model.add(BatchNormalization())                    \n",
    "model.add(Activation('relu')) \n",
    "model.add(Dense(500,kernel_initializer='he_normal'))\n",
    "model.add(BatchNormalization())                    \n",
    "model.add(Activation('relu'))  \n",
    "model.add(Dense(250,kernel_initializer='he_normal'))\n",
    "model.add(BatchNormalization())                    \n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(125,kernel_initializer='he_normal'))\n",
    "model.add(BatchNormalization())                    \n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(32,kernel_initializer='he_normal'))\n",
    "model.add(BatchNormalization())                    \n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(12,kernel_initializer='he_normal'))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "#updating learning rate\n",
    "adam = optimizers.Adam(lr=0.009, decay=1e-6)\n",
    "# Compile the model\n",
    "model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=\"adam\")\n",
    "\n",
    "# Fit the model\n",
    "history=model.fit(x=X_train, y=y_train, batch_size=50, epochs=25, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can notice the train accuracies are increasing close to 100% but validation accuracies are around 40% only\n",
    "- We will try to augment the train data and train it again so that we will get less overfitted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(X_test, y_test)\n",
    "print('Accuracy: %f ' % (results[1]*100))\n",
    "print('Loss: %f' % results[0])\n",
    "\n",
    "\n",
    "\n",
    "Y_pred_test_cls = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "plt.figure(figsize=(2,2))\n",
    "plt.imshow(X_test[300].reshape(32,32,3))\n",
    "plt.show()\n",
    "\n",
    "print('Label - one hot encoded: \\n',y_test_cat.iloc[300] )\n",
    "print('Actual Label - one hot encoded:  ', y_test[300])\n",
    "print('Predicted Label - one hot encoded: ',Y_pred_test_cls[300] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Test data set accuracies are around 35%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reimporting data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, random_state=42, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "one_hot_encoder.fit(y_train.reshape(-1, 1))\n",
    "\n",
    "y_train = one_hot_encoder.transform(y_train.reshape(-1, 1))\n",
    "#y_train = pd.DataFrame(data=y_train, columns=one_hot_encoder.categories_)\n",
    "\n",
    "y_test = one_hot_encoder.transform(y_test.reshape(-1, 1))\n",
    "#y_test = pd.DataFrame(data=y_test, columns=one_hot_encoder.categories_)\n",
    "\n",
    "y_val = one_hot_encoder.transform(y_val.reshape(-1, 1))\n",
    "#y_val = pd.DataFrame(data=y_val, columns=one_hot_encoder.categories_)\n",
    "\n",
    "\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "\n",
    "print(\"Shape of y_test:\", y_test.shape)\n",
    "\n",
    "print(\"Shape of y_val:\", y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_cat = pd.DataFrame(data=y_test, columns=one_hot_encoder.categories_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ImageDataGenerator is a preprocessing utility to generate training and testing data with common data augmentation techniques.\n",
    "- Used to generate training data from Images stored in hierarchical directory structures For more options of ImageDataGenerator go to https://keras.io/preprocessing/image/\n",
    "    - Rotaion Range -20\n",
    "    - Width Shift Range - 0.2\n",
    "    - Height Shift Range - 0.2\n",
    "    - Zoom Range - 0.4 to 1.5\n",
    "    - Horizontal flip - True\n",
    "    - Vertical Flip - True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen= tf.keras.preprocessing.image.ImageDataGenerator(rotation_range=20,\n",
    "                                                         width_shift_range=0.2,\n",
    "                                                         height_shift_range=0.2,\n",
    "                                                         zoom_range=[0.4,1.5],\n",
    "                                                         horizontal_flip=True,\n",
    "                                                         vertical_flip=True)\n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10000,kernel_initializer='he_normal'))\n",
    "model.add(BatchNormalization())                    \n",
    "model.add(Activation('relu')) \n",
    "model.add(Dense(1000,kernel_initializer='he_normal'))\n",
    "model.add(BatchNormalization())                    \n",
    "model.add(Activation('relu')) \n",
    "model.add(Dense(500,kernel_initializer='he_normal'))\n",
    "model.add(BatchNormalization())                    \n",
    "model.add(Activation('relu'))  \n",
    "model.add(Dense(250,kernel_initializer='he_normal'))\n",
    "model.add(BatchNormalization())                    \n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(125,kernel_initializer='he_normal'))\n",
    "model.add(BatchNormalization())                    \n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(32,kernel_initializer='he_normal'))\n",
    "model.add(BatchNormalization())                    \n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(12,kernel_initializer='he_normal'))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "#updating learning rate\n",
    "adam = optimizers.Adam(lr=0.01, decay=1e-6)\n",
    "# Compile the model\n",
    "model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=\"adam\")\n",
    "\n",
    "#Saving the best model using model checkpoint callback\n",
    "model_checkpoint=tf.keras.callbacks.ModelCheckpoint('plantspecies_NN_model.h5', #where to save the model\n",
    "                                                    save_best_only=True, \n",
    "                                                    monitor='val_accuracy', \n",
    "                                                    mode='max', \n",
    "                                                    verbose=1)\n",
    "\n",
    "history= model.fit_generator(datagen.flow(X_train, y_train, batch_size=16),  \n",
    "                  epochs=25, \n",
    "                  validation_data=(X_val, y_val),\n",
    "                  callbacks = [model_checkpoint])\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- With This model we can see the train and validation accuracies are close by and hence not a overfitted model\n",
    "- Still the accuracy results are less than 50%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(X_test, y_test)\n",
    "print('Accuracy: %f ' % (results[1]*100))\n",
    "print('Loss: %f' % results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(X_test, y_test)\n",
    "print('Accuracy: %f ' % (results[1]*100))\n",
    "print('Loss: %f' % results[0])\n",
    "\n",
    "\n",
    "\n",
    "Y_pred_test_cls = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "plt.figure(figsize=(2,2))\n",
    "plt.imshow(X_test[200].reshape(32,32,3))\n",
    "plt.show()\n",
    "\n",
    "print('Label - one hot encoded: \\n',y_test_cat.iloc[200] )\n",
    "print('Actual Label - one hot encoded:  ', y_test[200])\n",
    "print('Predicted Label - one hot encoded: ',Y_pred_test_cls[200] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- With Neural network we were able to improve test set predictions to close to 40%.\n",
    "- Even with NN we are struggling for image identification with high accuracies.\n",
    "- Epochs were limited at 25 only as we will be comparing the same with CNN on similar grounds. We may acheive a bit higher accuracies with more epochs.\n",
    "- NN is able to provide better result compared to KNN but it has high computation requirement and huge data to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Classification with CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential  # initial NN\n",
    "from tensorflow.keras.layers import Dense, Dropout # construct each layer\n",
    "from tensorflow.keras.layers import Conv2D # swipe across the image by 1\n",
    "from tensorflow.keras.layers import MaxPooling2D # swipe across by pool size\n",
    "from tensorflow.keras.layers import Flatten, GlobalAveragePooling2D\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, random_state=42, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "one_hot_encoder.fit(y_train.reshape(-1, 1))\n",
    "\n",
    "y_train = one_hot_encoder.transform(y_train.reshape(-1, 1))\n",
    "#y_train = pd.DataFrame(data=y_train, columns=one_hot_encoder.categories_)\n",
    "\n",
    "y_test = one_hot_encoder.transform(y_test.reshape(-1, 1))\n",
    "#y_test = pd.DataFrame(data=y_test, columns=one_hot_encoder.categories_)\n",
    "\n",
    "y_val = one_hot_encoder.transform(y_val.reshape(-1, 1))\n",
    "#y_val = pd.DataFrame(data=y_val, columns=one_hot_encoder.categories_)\n",
    "\n",
    "\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "\n",
    "print(\"Shape of y_test:\", y_test.shape)\n",
    "\n",
    "print(\"Shape of y_val:\", y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_cat = pd.DataFrame(data=y_test, columns=one_hot_encoder.categories_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (5, 5), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "\n",
    "\n",
    "\n",
    "model.add(Dense(12, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history=model.fit(x=X_train, y=y_train, batch_size=50, epochs=25, validation_data=(X_val, y_val))\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- With a very basic CNN model also we can see the validation accuracies are close to 70%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(X_test, y_test)\n",
    "print('Accuracy: %f ' % (results[1]*100))\n",
    "print('Loss: %f' % results[0])\n",
    "\n",
    "\n",
    "\n",
    "Y_pred_test_cls = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "plt.figure(figsize=(2,2))\n",
    "plt.imshow(X_test[300].reshape(32,32,3))\n",
    "plt.show()\n",
    "\n",
    "print('Label - one hot encoded: \\n',y_test_cat.iloc[300] )\n",
    "print('Actual Label - one hot encoded:  ', y_test[300])\n",
    "print('Predicted Label - one hot encoded: ',Y_pred_test_cls[300] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding few additional layers in model for it to capture more features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (5, 5), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(BatchNormalization()) \n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=4, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(BatchNormalization()) \n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(filters=256, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(12, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "#updating learning rate\n",
    "adam = optimizers.Adam(lr=0.009, decay=1e-6)\n",
    "\n",
    "# compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#Saving the best model using model checkpoint callback\n",
    "model_checkpoint=tf.keras.callbacks.ModelCheckpoint('plantspecies_CNN_model.h5', #where to save the model\n",
    "                                                    save_best_only=True, \n",
    "                                                    monitor='val_accuracy', \n",
    "                                                    mode='max', \n",
    "                                                    verbose=1)\n",
    "\n",
    "history=model.fit(x=X_train, y=y_train, \n",
    "                  batch_size=50, \n",
    "                  epochs=25, \n",
    "                  validation_data=(X_val, y_val),\n",
    "                  callbacks = [model_checkpoint])\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can observe now the validation accuracies are increased closed to 80%\n",
    "- still there is a noticable gap betweeen train and validation accuracies, will try to close the gap in further models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(X_test, y_test)\n",
    "print('Accuracy: %f ' % (results[1]*100))\n",
    "print('Loss: %f' % results[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Test data set accuracies are immproved closed to 80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Traing the model with augmented data set and 500 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ImageDataGenerator is a preprocessing utility to generate training and testing data with common data augmentation techniques.\n",
    "- Used to generate training data from Images stored in hierarchical directory structures For more options of ImageDataGenerator go to https://keras.io/preprocessing/image/\n",
    "    - Rotaion Range -20\n",
    "    - Width Shift Range - 0.2\n",
    "    - Height Shift Range - 0.2\n",
    "    - Zoom Range - 0.4 to 1.5\n",
    "    - Horizontal flip - True\n",
    "    - Vertical Flip - True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen= tf.keras.preprocessing.image.ImageDataGenerator(rotation_range=20,\n",
    "                                                         width_shift_range=0.2,\n",
    "                                                         height_shift_range=0.2,\n",
    "                                                         zoom_range=[0.4,1.5],\n",
    "                                                         horizontal_flip=True,\n",
    "                                                         vertical_flip=True)\n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (5, 5), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(BatchNormalization()) \n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=4, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(BatchNormalization()) \n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(filters=256, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(12, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "#updating learning rate\n",
    "adam = optimizers.Adam(lr=0.009, decay=1e-6)\n",
    "\n",
    "# compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#Saving the best model using model checkpoint callback\n",
    "model_checkpoint=tf.keras.callbacks.ModelCheckpoint('plantspecies_CNN_model.h5', #where to save the model\n",
    "                                                    save_best_only=True, \n",
    "                                                    monitor='val_accuracy', \n",
    "                                                    mode='max', \n",
    "                                                    verbose=1)\n",
    "\n",
    "history= model.fit_generator(datagen.flow(X_train, y_train, batch_size=32),  \n",
    "                  epochs=500, \n",
    "                  validation_data=(X_val, y_val))\n",
    "                  #callbacks = [model_checkpoint])\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can notice the train and test accuracies are overlaping\n",
    "- This model is less overfitted and providing us with close to 90% accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(X_test, y_test)\n",
    "print('Accuracy: %f ' % (results[1]*100))\n",
    "print('Loss: %f' % results[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Test data set accuracies are improved close to 90%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "157MBWfwVORb"
   },
   "source": [
    "**Always save the model and its weights after training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WwvESxvvzRgz"
   },
   "outputs": [],
   "source": [
    "model.save('./Plant_Species_Classifier_500.h5')\n",
    "\n",
    "model.save_weights('./Plant_Species_Classifier_weights_500.h5')\n",
    "\n",
    "#we can save using keras methods and job lib as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XKfWmfnTVWbO"
   },
   "source": [
    "<h2>Let's test the model now</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KRXKNJjWVzGq"
   },
   "source": [
    "**Load the pre-trained saved model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tB5k1sCWVwJt"
   },
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Load the pre trained model from the HDF5 file saved previously\n",
    "pretrained_model = load_model('./Plant_Species_Classifier_500.h5')\n",
    "pretrained_model.load_weights('./Plant_Species_Classifier_weights_500.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8iFL22MKV-nB"
   },
   "source": [
    "**Testing the model on a test image from one of the test folders**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pretrained_model.evaluate(X_test, y_test)\n",
    "print('Accuracy: %f ' % (results[1]*100))\n",
    "print('Loss: %f' % results[0])\n",
    "\n",
    "\n",
    "\n",
    "Y_pred_test_cls = (pretrained_model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "plt.figure(figsize=(2,2))\n",
    "plt.imshow(X_test[300].reshape(32,32,3))\n",
    "plt.show()\n",
    "\n",
    "print('Label - one hot encoded: \\n',y_test_cat.iloc[300] )\n",
    "print('Actual Label - one hot encoded:  ', y_test[300])\n",
    "print('Predicted Label - one hot encoded: ',Y_pred_test_cls[300] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- With CNN we are able to achieve close to 90% accuracies with train, validation and test data.\n",
    "- We can notice the train and validation accuracies are close to each other at higher epochs.\n",
    "- we will be using the same for prediction of rest of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the images from test folder and generate test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can not directly use the image, we have to process the image.\n",
    "\n",
    "from pathlib import Path\n",
    "from skimage.io import imread\n",
    "from keras.preprocessing import image\n",
    "import cv2 as cv\n",
    "def load_test_files(container_path):\n",
    "    image_dir = Path(container_path)\n",
    "\n",
    "    images = []\n",
    "    flat_data = []\n",
    "    target = []\n",
    "    count = 0\n",
    "    train_img = []\n",
    "    fileNames = []\n",
    "    for file in image_dir.iterdir():\n",
    "        count += 1\n",
    "        img = imread(file)\n",
    "        img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "        img_pred = cv.resize(img, (32, 32), interpolation=cv.INTER_AREA)\n",
    "        img_pred = image.img_to_array(img_pred)\n",
    "        img_pred = img_pred / 255\n",
    "        train_img.append(img_pred)\n",
    "        head, tail = os.path.split(file)\n",
    "        fileNames.append(tail)\n",
    "            \n",
    "    X = np.array(train_img)\n",
    "    y = np.array(fileNames)\n",
    "    return X,y\n",
    "\n",
    "#Using the Keras pre-processing library the image is converted to an array and then normalised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sub,FileNames_Test=load_test_files(specPathTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FileNames_Test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FileNames_Test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_test_cls = (pretrained_model.predict(X_sub) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_test_cls[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_cat = pd.DataFrame(data=Y_pred_test_cls, columns=one_hot_encoder.categories_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_subm_cat=one_hot_encoder.inverse_transform(y_test_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_subm_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_subm_cat=y_subm_cat.reshape(y_subm_cat.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=pd.DataFrame({\"file\":FileNames_Test,\"species\":y_subm_cat})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2,2))\n",
    "plt.imshow(X_sub[0].reshape(32,32,3))\n",
    "plt.show()\n",
    "print(res.species[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2,2))\n",
    "plt.imshow(X_sub[1].reshape(32,32,3))\n",
    "plt.show()\n",
    "print(res.species[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2,2))\n",
    "plt.imshow(X_sub[2].reshape(32,32,3))\n",
    "plt.show()\n",
    "print(res.species[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.to_csv(\"submission_PlantClassification.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Part 2 : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explain in depth why CNN out performs neural networks which in turn out perform supervised learning models when it comes to image classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - For this question we have to divide the models into two major groups:\n",
    "     - Machine learning Algorithms\n",
    "     - Deep Neural Networks (NN & CNN)\n",
    "\n",
    " - Machine Learning Algorithms:\n",
    "     - these algo's learn their mapping from provided input and output i.e. alog learns a function with diff sets of weight which help in predicting the accurate values.\n",
    "     - For classification algorithms they learns from the term being used \"Decision Boundries\"\n",
    "     - These decision boundries determine wether a new point belongs to which class or groups\n",
    "     - Decision boundries could vary from linear to non-linear and these algo's are very strong to identify any relationship and map it with proper function and weight.\n",
    "     - Image classification althoug a classification problem but it has much more details and relationships which ML Decision boundries are not able to map and replicate without very high computation and some times even thats not enough and becomme impossible for usinng these algos.\n",
    "     \n",
    " - Deep Neural Netowrks ( ANN & CNN ):\n",
    "     - Deep Neural networks brought in a different concept called Feature Engineering\n",
    "         - Feature Extraction\n",
    "         - Feature Selection\n",
    "     - In feature extraction, we extract all the required features for our problem statement\n",
    "     - In feature selection, we select the important features that improve the performance of our deep learning model.\n",
    "     - By this design change in model is giving us huge advantage over Machine learning algorithms for identifying important features of the image and relationships with outputs which helps in categorizing/predictiong classes more accurately.\n",
    "     \n",
    " - Chalanges for Neural Network:\n",
    "     - NN amount of weight become unmanagable becuse it uses one perceptron for each input/pixel\n",
    "     - too many parameters as its fully connected\n",
    "     - each node is connected to previous and next layer making it very dense and many connections are redundant\n",
    "     - Translation Invariant - NN behaves differently to shifted version of same image/zoomed/inverted. To make it learn all those you have to feed all varaions of data, which is higly difficult.\n",
    "     - NN expects an identified object should appear on that specific place only which is never the real world scenario.\n",
    "     - spatial information is lost when the image is flattened(matrix to vector)\n",
    "     - This will make image processing difficult as the model will tend to overfit and capture unnecessary relationship\n",
    "     \n",
    " - CNN Advantages:\n",
    "\n",
    "    - Convolution:\n",
    "         - feed forward NN wont see any order in their inputs\n",
    "         - CNN on other hand is better at dealing with multiple kinds of spatial deformations. It take advantage of local spatial coherence of images. \n",
    "         - This means that they are able to reduce dramatically the number of operation needed to process an image by using convolution on patches of adjacent pixels, because adjacent pixels together are meaningful. \n",
    "         - We also call that local connectivity.\n",
    "         - convolution in neural networks is operation of finding patterns. It has kernel that with which it basically scan an image and place where kernel have 100% match is a place where pattern matched. \n",
    "    - Pooling layers:\n",
    "        - downscale the image\n",
    "        - This is possible because we retain throughout the network, features that are organized spatially like an image, and thus downscaling them makes sense as reducing the size of the image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
